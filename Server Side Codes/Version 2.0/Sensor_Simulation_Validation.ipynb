{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import xml.etree.ElementTree\n",
    "motion_sensors = [1, 10, 11, 12, 13, 14, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "global sensors_list\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from math import sqrt\n",
    "\n",
    "sensors_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UltimateDatasetName1 = \"Data//Results//Ultimate_Dataset_28jun1\"\n",
    "title1 = \"28 June - 1st Session\"\n",
    "UltimateDatasetName2 = \"Data//Results//Ultimate_Dataset_28jun2\"\n",
    "title2 = \"28 June - 2nd Session\"\n",
    "UltimateDatasetName3 = \"Data//Results//Ultimate_Dataset_4jul1\"\n",
    "title3 = \"4 July - 1st Session\"\n",
    "UltimateDatasetName4 = \"Data//Results//Ultimate_Dataset_4jul2\"\n",
    "title4 = \"4 July - 2nd Session\"\n",
    "simworldname = 'Data//simulationWorld2.xml'\n",
    "\n",
    "UltimateDatasetNames = [UltimateDatasetName1, UltimateDatasetName2, \n",
    "                        UltimateDatasetName3, UltimateDatasetName4]\n",
    "titles = [title1, title2, title3, title4]\n",
    "\n",
    "max_half_window_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindClosestDataPoint(item, reference_list, lower_limit, upper_limit):\n",
    "    temp_list = reference_list.copy()\n",
    "    lower_limit = int(lower_limit)\n",
    "    upper_limit = int(upper_limit)\n",
    "    ind = lower_limit\n",
    "    \n",
    "    diff = abs(item - temp_list[lower_limit])\n",
    "    for i in range(lower_limit, upper_limit):\n",
    "        new_diff = abs(item - temp_list[i])\n",
    "        if (new_diff < diff):\n",
    "            diff = new_diff\n",
    "            ind = i\n",
    "        if (diff == 0):\n",
    "            break\n",
    "    # temp_list[ind] = -1\n",
    "    return ind\n",
    "\n",
    "def SlidingWindowDataMatching(synt_sensor_seq, real_sensor_seq, window_size):\n",
    "    L = synt_sensor_seq.copy()\n",
    "    matching_list = []\n",
    "    speed = len(L) / len(real_sensor_seq)\n",
    "    j = 0\n",
    "    for i in range(len(real_sensor_seq)):\n",
    "        if (not (real_sensor_seq[i] == -1)):\n",
    "            if (j - window_size < 0): lower_limit = 0\n",
    "            else: lower_limit = j - window_size\n",
    "            if (j + window_size > len(L)): upper_limit = len(L)\n",
    "            else: upper_limit = j + window_size\n",
    "            \n",
    "            ind = FindClosestDataPoint(real_sensor_seq[i], L, lower_limit, upper_limit)\n",
    "            matching_list.append(L[ind])\n",
    "            # L[ind] = -1\n",
    "        j = (i+1) * speed\n",
    "    return matching_list\n",
    "\n",
    "def GetSensorsDictionary(df_):\n",
    "    gt_readings = []\n",
    "    sy_readings = []\n",
    "    for i in range(len(df_)):\n",
    "        gt_readings.append(ast.literal_eval(df_.gt_motion_readings[i]))\n",
    "        sy_readings.append(ast.literal_eval(df_.synthetic_motion_readings[i]))\n",
    "        \n",
    "    return np.asarray(gt_readings).T, np.asarray(sy_readings).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "precisions = {}\n",
    "recalls = {}\n",
    "rmses = {}\n",
    "\n",
    "test = {}\n",
    "test2 = {}\n",
    "PRF = {}\n",
    "\n",
    "for S in range(1, 15):\n",
    "    print(S)\n",
    "    if (S < 9 or S > 12):\n",
    "        precisions[S] = {}\n",
    "        PRF[S] = {}\n",
    "        recalls[S] = {}\n",
    "        rmses[S] = {}\n",
    "        test[S] = {}\n",
    "        test2[S] = {}\n",
    "        for U in UltimateDatasetNames:\n",
    "            df_ = (pd.read_csv(U + \".csv\"))\n",
    "            gt_sensors, sy_sensors = GetSensorsDictionary(df_)\n",
    "\n",
    "            PRF[S][U] = []\n",
    "            precisions[S][U] = []\n",
    "            recalls[S][U] = []\n",
    "            rmses[S][U] = []\n",
    "            \n",
    "            test[S][U] = gt_sensors[:S].tolist()[0]\n",
    "            test2[S][U] = sy_sensors[:S].tolist()[0]\n",
    "            \n",
    "            for window_size in range(1, max_half_window_size + 1):\n",
    "                matching_list = SlidingWindowDataMatching(sy_sensors[:S].tolist()[0] , gt_sensors[:S].tolist()[0], window_size)\n",
    "                \n",
    "                PRF[S][U].append(precision_recall_fscore_support(matching_list, gt_sensors[:S].tolist()[0], average='weighted'))\n",
    "                \n",
    "                if window_size == 5:\n",
    "                    cm = confusion_matrix(gt_sensors[:S].tolist()[0], matching_list, labels=[0, 1])\n",
    "                    print(cm)\n",
    "\n",
    "                # fig, ax = plt.subplots()\n",
    "                # im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Greens)\n",
    "                # ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "                # precisions[S][U].append(precision_score(matching_list, gt_sensors[:S].tolist()[0], average='micro'))\n",
    "                # recalls[S][U].append(recall_score(matching_list, gt_sensors[:S].tolist()[0], average='micro'))\n",
    "                # rmses[S][U].append(sqrt(mean_squared_error(matching_list, gt_sensors[:S].tolist()[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Print2(D, titles, metric, max_half_window_size):\n",
    "    if (metric == 'PRF'):\n",
    "        for m in range(3):\n",
    "            fig, ax = plt.subplots(figsize = (9, 5))\n",
    "            styles = ['-', '--', ':', '-.']\n",
    "            for i in range(len(titles)):\n",
    "                temp_list = []\n",
    "                for w in range(100):\n",
    "                    temp_list.append(D[titles[i]][w][m])\n",
    "                \n",
    "                plt.plot([(i * 6)/60 for i in range(1, max_half_window_size + 1)], temp_list, styles[i], color = 'k')\n",
    "\n",
    "            plt.grid(color='k', linestyle=':', linewidth=0.5)\n",
    "            # plt.subplots(figsize = (9, 5))\n",
    "            plt.yticks(np.arange(0.8, 1.1, 0.05))\n",
    "            plt.xticks(np.arange(0, 11, 1.0))\n",
    "            plt.xlabel(\"Window Size (Minutes)\")\n",
    "            if (m == 0): plt.ylabel(\"Precision\")\n",
    "            elif(m == 1): plt.ylabel(\"Recall\")\n",
    "            elif(m == 2): plt.ylabel(\"F-Score\")\n",
    "                \n",
    "\n",
    "            plt.legend(titles)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "def Print(D, UltimateDatasetNames, metric, max_half_window_size, titles):\n",
    "    fig, ax = plt.subplots(figsize = (9, 5))\n",
    "    styles = ['-', '--', ':', '-.']\n",
    "    for i in range(len(UltimateDatasetNames)):\n",
    "        plt.plot([(i * 6)/60 for i in range(1, max_half_window_size + 1)], \n",
    "                 D[UltimateDatasetNames[i]], styles[i], color = 'k')\n",
    "    \n",
    "    plt.grid(color='k', linestyle=':', linewidth=0.5)\n",
    "    # plt.subplots(figsize = (9, 5))\n",
    "    plt.xticks(np.arange(0, 11, 1.0))\n",
    "    plt.xlabel(\"Window Size (Minutes)\")\n",
    "    plt.ylabel(metric)\n",
    "    \n",
    "    plt.legend(titles)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for S in range(1, 15):\n",
    "    if (S < 9 or S > 12):\n",
    "        print(S)\n",
    "        Print2(PRF[S], UltimateDatasetNames, 'PRF', max_half_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "title = 'Normalized confusion matrix'\n",
    "\n",
    "\n",
    "for U in UltimateDatasetNames:\n",
    "    if (U == \"Data//Results//Ultimate_Dataset_28jun2\"):\n",
    "        rr = real_data_dict[U]['data'][:1510]\n",
    "    else:\n",
    "        rr = real_data_dict[U]['data']\n",
    "        \n",
    "    mm = matching_list_dict[U][50]\n",
    "    \n",
    "    cm = confusion_matrix(rr, mm)\n",
    "    \n",
    "    print(cm)\n",
    "    # cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Greens)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "               \n",
    "    classes = unique_labels(rr, mm)\n",
    "    \n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label') \n",
    "    \n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    \n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gt_sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
